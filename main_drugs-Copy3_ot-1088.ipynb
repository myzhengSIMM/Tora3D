{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7e24e628",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pre_data_f import pre_data\n",
    "from cheek_pred_effect import construct_test_loader_by_dic\n",
    "\n",
    "from model_ import PosEmb_Seq2eq\n",
    "# from utils import count_parameters\n",
    "# from utils import pad_list\n",
    "\n",
    "from cheek_pred_effect import generate_pred_confs \n",
    "from utils_base import pickle_\n",
    "from utils_base import info\n",
    "from utils_base import repeat_list_by_numlist\n",
    "from utils_base import group_by_num\n",
    "from utils_base import reorder\n",
    "\n",
    "from utils_others import extract_mol_from_chemdir\n",
    "from utils_others import rotate_a_mol\n",
    "from utils_others import writosdf\n",
    "\n",
    "\n",
    "from utils import count_parameters\n",
    "\n",
    "from loops import batch_inference, inference\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.optim import Adam\n",
    "import copy\n",
    "import os.path as osp\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# from dgllife.utils import Meter\n",
    "# from functools import partial\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# torch.set_printoptions(profile=\"full\")  \n",
    "torch.set_printoptions(sci_mode=False) \n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a0f155be",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"./data_1\"\n",
    "ol = \"drugs\"\n",
    "nam = \"1088\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2d917cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "chem_dataset_dir = \"data_1/rdkit_folder/drugs\"\n",
    "\n",
    "test_dic_path = f\"./prepare_ori_con/test_{nam}_dic.pkl\"\n",
    "\n",
    "smiles_list_path = osp.join(path, ol, \"smiles_list.pkl\" )          \n",
    "torsion_idx_list_path = osp.join(path, ol, \"torsion_idx_list.pkl\")\n",
    "\n",
    "torsion_list_path = osp.join(path, ol, \"torsion_list.pkl\")\n",
    "relativeenergy_list_path = osp.join(path, ol, \"relativeenergy_list.pkl\")\n",
    "\n",
    "batch_size = 16\n",
    "\n",
    "max_Emb_wl = 40    \n",
    "max_Emb_d = 10     \n",
    "\n",
    "# generate feat\n",
    "max_num_atom=90\n",
    "wl_max_iter=3\n",
    "num_choosed_confs = 12000\n",
    "\n",
    "\n",
    "rate_trte=0.9\n",
    "rate_tr_in_trti=0.8\n",
    "\n",
    "\n",
    "print_every = 100\n",
    "model_save_every = 10000\n",
    "\n",
    "# epochs\n",
    "num_epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "06168b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PosEmb_Seq2eq(          # 4 * (node_feat_dim + outp_dim*3) + 3 * edge_feat_dim \n",
    "\n",
    "    pf_dim_pos=32,\n",
    "    pf_dim1=32,  # I take 256\n",
    "    pf_dim2=32,  # I take 256\n",
    "    max_Emb_wl=max_Emb_wl,   \n",
    "    max_Emb_d=max_Emb_d,\n",
    "\n",
    "    # pf_dim_readout=256,  # I take 256\n",
    "    outp_dim=16,  # I take 16\n",
    "    trg_emb_dim=32,\n",
    "\n",
    "    ENC_LAYERS=1,\n",
    "    ENC_HEADS=5, \n",
    "    ENC_PF_DIM=32,\n",
    "    DEC_LAYERS=3,\n",
    "    DEC_HEADS=4,\n",
    "    DEC_PF_DIM=32,\n",
    "    device=device,\n",
    "    \n",
    "    t_e_ENC_LAYERS=1,\n",
    "    t_e_ENC_HEADS=5,   \n",
    "    t_e_ENC_PF_DIM=32,\n",
    "    \n",
    "    noise_dim = 100,\n",
    "    noise_loc=0, \n",
    "    noise_scale=5,\n",
    "    \n",
    "    edge_feat_dim=10,\n",
    "    node_feat_dim=39,\n",
    "    dropout=0.1,\n",
    "    max_num_atom=max_num_atom\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fad0a299",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_criterion = nn.MSELoss()   # ignore_index = TRG_PAD_IDX  \n",
    "# loss_criterionn = nn.MSELoss()   # ignore_index = TRG_PAD_IDX  \n",
    "\n",
    "loss_criterion_= nn.CrossEntropyLoss()\n",
    "optimizer = Adam(model.parameters(), lr = 0.0005,\n",
    "                 weight_decay=10 ** -5\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c0e3a27c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting......\n",
      "2023-04-26 13:54:38\n",
      "done\n",
      "2023-04-26 13:55:12\n",
      "185469 185469 185469 185469\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"starting......\")\n",
    "print (time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime()))\n",
    "smilelist = pickle_.load(smiles_list_path)\n",
    "torsion_angle = pickle_.load(torsion_list_path)\n",
    "torsion_list = pickle_.load(torsion_idx_list_path)\n",
    "relativeenergy_list = pickle_.load(relativeenergy_list_path)\n",
    "\n",
    "# torsion_angle = [list(zip(torsion[0],(np.array(torsion[1])+1).tolist())) for torsion in torsion_angle]\n",
    "\n",
    "print(\"done\")\n",
    "print (time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime()) )\n",
    "print(len(smilelist), len(torsion_angle), len(torsion_list), len(relativeenergy_list))\n",
    "torsion_angle[0].device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "21f2ebdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9274 1160 1160\n"
     ]
    }
   ],
   "source": [
    "train_loader, val_loader, test_loader = pre_data(\n",
    "    smilelist, torsion_list, torsion_angle, relativeenergy_list, batch_size,\n",
    "    rate_trte, rate_tr_in_trti, max_num_atom, wl_max_iter, num_choosed_confs, \n",
    "    device = device\n",
    "     )\n",
    "print(len(train_loader),  len(val_loader), len(test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "618d562f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gpu2-data1/zhangzimei/work_now/Tora3D/Tora3D/cheek_pred_effect.py:59: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
      "  torsion_angle_200 = list(np.array([t.cpu() for t in torsion_angle])[idxs])\n",
      "/home/gpu2-data1/zhangzimei/work_now/Tora3D/Tora3D/cheek_pred_effect.py:59: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  torsion_angle_200 = list(np.array([t.cpu() for t in torsion_angle])[idxs])\n",
      "/home/gpu2-data1/zhangzimei/work_now/Tora3D/Tora3D/cheek_pred_effect.py:60: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
      "  torsion_list_200 = list(np.array([t.cpu() for t in torsion_list])[idxs])\n",
      "/home/gpu2-data1/zhangzimei/work_now/Tora3D/Tora3D/cheek_pred_effect.py:60: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  torsion_list_200 = list(np.array([t.cpu() for t in torsion_list])[idxs])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(test_loader) 68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gpu2-data1/zhangzimei/work_now/Tora3D/Tora3D/cheek_pred_effect.py:61: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  relativeenergy_list_200 = list(np.array(relativeenergy_list)[idxs])\n"
     ]
    }
   ],
   "source": [
    "test_loader = construct_test_loader_by_dic(test_dic_path, \n",
    "                                            smilelist,\n",
    "                                            torsion_angle,\n",
    "                                            torsion_list,\n",
    "                                            relativeenergy_list,\n",
    "                                            batch_size,\n",
    "                                            max_num_atom, \n",
    "                                            wl_max_iter, \n",
    "                                            num_choosed_confs, \n",
    "                                            device = device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fbdb6388",
   "metadata": {},
   "outputs": [],
   "source": [
    "#     for batch_id, batch_data in enumerate(train_loader):\n",
    "#         atom_feat, AM_bond_feat, node_color_feat, d, labels, masks, relativeenergys, num_atom_list, angle_group_num, num_confs_list, smiles_list = batch_data\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "25cd24a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_orderM(prediction,labels, num_confs_list,angle_group_num):\n",
    "\n",
    "    prediction_t = torch.cat([prediction[:,:,0:1], prediction[:,:,1:].argmax(-1).unsqueeze(-1)-1],-1)    \n",
    "    pred_angles = (prediction_t[:,:,0]+0.5)*180*prediction_t[:,:,1]\n",
    "    true_angles = (labels[:,:,0]+0.5)*180*labels[:,:,1]\n",
    "\n",
    "\n",
    "    prediction_tense = group_by_num(pred_angles, num_confs_list)\n",
    "    labels_tense = group_by_num(true_angles, num_confs_list)\n",
    "    prediction_tense_ = [prediction_tense[index][:,:group].detach().cpu().numpy() for index,group in enumerate(angle_group_num)]\n",
    "    labels_tense_     = [labels_tense[index][:,:group].detach().cpu().numpy()     for index,group in enumerate(angle_group_num)]\n",
    "\n",
    "    orderM_list = [torch.tensor(reorder(p,l)[2], dtype=torch.float32) for p,l in zip(prediction_tense_, labels_tense_)]\n",
    "    return orderM_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "283c16a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_a_train_epoch( epoch, model, data_loader, loss_criterion, loss_criterion_, optimizer):\n",
    "    device = model.device\n",
    "    model.train()\n",
    "    covr_best = 0\n",
    "    k = 0\n",
    "    for batch_id, batch_data in enumerate(train_loader):\n",
    "        atom_feat, AM_bond_feat, node_color_feat, d, labels, masks, relativeenergys, num_atom_list, angle_group_num, num_confs_list, smiles_list = batch_data\n",
    "        batchsize = len(num_confs_list)\n",
    "        \n",
    "        prediction = model(device, \n",
    "        atom_feat, AM_bond_feat, node_color_feat, d, labels, masks, relativeenergys, num_atom_list, angle_group_num, num_confs_list, smiles_list)\n",
    "        \n",
    "        orderM_list = count_orderM(prediction,labels, num_confs_list,angle_group_num)\n",
    "\n",
    "        prediction_tense = group_by_num(prediction, num_confs_list)\n",
    "        labels_tense     = group_by_num(labels, num_confs_list)\n",
    "        prediction_tense_ = [prediction_tense[index][:,:group] for index,group in enumerate(angle_group_num)]\n",
    "        labels_tense_  = [torch.mm(orderM_list[index].to(device),\n",
    "            labels_tense[index][:,:group].reshape(labels_tense[index].shape[0],-1)).reshape(labels_tense[index].shape[0],-1,2) \n",
    "                             for index,group in enumerate(angle_group_num)]\n",
    "        loss = 0\n",
    "        for i in range(batchsize):\n",
    "            loss_value = loss_criterion(prediction_tense_[i][:,:,0],labels_tense_[i][:,:,0])\n",
    "            loss_sig = loss_criterion_(prediction_tense_[i][:,:,1:].permute(0,2,1), \n",
    "                               (labels_tense_[i][:,:,1]+1).long())/10\n",
    "            loss_ = loss_value+loss_sig\n",
    "            loss+=loss_\n",
    "        loss = loss/batchsize\n",
    "      \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if batch_id % print_every == 0:\n",
    "            print(time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime()))\n",
    "            \n",
    "            print('epoch {:d}/{:d}, batch {:d}/{:d}, loss {:.4f}'.format(\n",
    "                epoch + 1, num_epochs, batch_id + 1, len(data_loader), loss.item()))\n",
    "            print(\"loss_value:\",loss_value.item())\n",
    "            print(\"loss_sig:\",loss_sig.item())\n",
    "            print(\"loss:\",loss.item())\n",
    "\n",
    "            model.noise_scale = 100\n",
    "            \n",
    "            matr_,matp_,covr_,covp_,\\\n",
    "                lab_angles_allconfs_list_list,angles_allconfs_list_list= generate_pred_confs(model, test_loader, \n",
    "                                                                        loss_criterion, loss_criterion_, \n",
    "                                                                        save_conf_root=\"./confs_save\",\n",
    "                                                                        chem_dataset_dir = chem_dataset_dir,\n",
    "                                                                        ori_confs_path  = test_dic_path,                                                                 \n",
    "                                                                        optimizer=None, \n",
    "                                                                        debug = False,\n",
    "                                                                        angle_range_list = [(-20,20),(40,100)],\n",
    "                                                                        k = \"2\",\n",
    "                                                                        max_re = 6,\n",
    "                                                                        kn = 2,\n",
    "                                                                        f_percent=0.25,\n",
    "                                                                        part_batch=(0,6)\n",
    "                                                                          )\n",
    "            print(\"epoch:\", epoch, \"   covr_:\",covr_)\n",
    "            k+=1\n",
    "            if covr_ > covr_best:\n",
    "                covr_best = covr_\n",
    "                batch_id_best = batch_id\n",
    "                model_best = model\n",
    "                k = 0\n",
    "                print(f\"so far the best is {covr_best}\")\n",
    "            if k == 10:\n",
    "                print(f\"{k} times no more improvement， So far，the best is: {batch_id_best}/{len(data_loader)} _ {covr_best}\")\n",
    "                break\n",
    "        if batch_id % model_save_every == 0:\n",
    "            print(\"saved\")\n",
    "    return batch_id_best,covr_best,model_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "13ee38d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_an_eval_epoch(epoch, model, data_loader, loss_criterion, loss_criterion_, optimizer=None):\n",
    "\n",
    "    model.eval()\n",
    "    loss_values_list = []\n",
    "    loss_siges_list = []\n",
    "    losses_list = []\n",
    "    acc_sig_list = []\n",
    "#     Labels = []\n",
    "#     Prediction = []\n",
    "    with torch.no_grad():\n",
    "        for batch_id, batch_data in enumerate(data_loader):\n",
    "            atom_feat, AM_bond_feat, node_color_feat, d, labels, masks, relativeenergys, num_atom_list, angle_group_num, num_confs_list = batch_data\n",
    "\n",
    "            prediction = model(device, atom_feat, AM_bond_feat, node_color_feat, d, labels, masks, relativeenergys, num_atom_list, angle_group_num, num_confs_list)\n",
    "\n",
    "            prediction_ = torch.cat([prediction[index][0: group] for index,group in enumerate(repeat_list_by_numlist(angle_group_num,num_confs_list))])\n",
    "            labels_ = torch.cat([labels[index][0: group] for index, group in enumerate(repeat_list_by_numlist(angle_group_num,num_confs_list))])        \n",
    "\n",
    "            loss_value = loss_criterion(prediction_[:,0], labels_[:,0]).item()\n",
    "            loss_sig=loss_criterion_(prediction_[:,1:], (labels_[:,1]+1).long()).item()/10\n",
    "            loss = loss_value+loss_sig\n",
    "            acc_sig = ((prediction_[:,1:].argmax(-1)-1 == labels_[:,1]).sum()/len(labels_)).item()\n",
    "            \n",
    "            loss_values_list.append(loss_value)\n",
    "            loss_siges_list.append(loss_sig)\n",
    "            losses_list.append(loss)        \n",
    "            acc_sig_list.append(acc_sig)\n",
    "            \n",
    "#             if batch_id == 100:\n",
    "#                 break\n",
    "    loss_value = np.mean(loss_values_list)\n",
    "    loss_sig = np.mean(loss_siges_list)\n",
    "    loss = np.mean(losses_list)\n",
    "    acc_sig = np.mean(acc_sig_list)\n",
    "    \n",
    "    return loss_value, loss_sig, loss, acc_sig "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c33fbb3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load model\n",
    "cheekpoint = torch.load('model_save/model_save_main_drugs-Copy3ot_2022-06-14_20h10m42s.pth')\n",
    "model.load_state_dict(cheekpoint['model'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ae97bb1",
   "metadata": {},
   "source": [
    "### for higher score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b1cd36f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime()))\n",
    "model.noise_scale = 100\n",
    "\n",
    "matr_,matp_,covr_,covp_,df,\\\n",
    "lab_angles_allconfs_list_list,angles_allconfs_list_list,_list,\\\n",
    "smiles_list,num_confs_list_list,num_atom_list_list,angle_group_num_list= generate_pred_confs(model, test_loader, \n",
    "                                                            loss_criterion, loss_criterion_, \n",
    "                                                            # save_conf_root=\"./confs_save\",\n",
    "                                                            chem_dataset_dir = chem_dataset_dir,\n",
    "                                                            ori_confs_path  = test_dic_path,                                                                 \n",
    "                                                            optimizer=None, \n",
    "                                                            debug = False,\n",
    "                                                            angle_range_list = [(-20,20),(40,100)],\n",
    "                                                            k = \"2\",\n",
    "                                                            max_re = 6,\n",
    "                                                            kn = 2,\n",
    "                                                            f_percent=0.25,\n",
    "                                                            # part_batch = [0,20]\n",
    "                                                                                )\n",
    "\n",
    "\n",
    "time_save = time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime())\n",
    "print(time_save)\n",
    "pickle_.save(f\"./result_save/result_{nam}_{time_save}.pkl\", (matr_,matp_,covr_,covp_,df))\n",
    "print(matr_,matp_,covr_,covp_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ff4a3f5",
   "metadata": {},
   "source": [
    "### for more reasonable structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "42c8b83c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime()))\n",
    "model.noise_scale = 100\n",
    "\n",
    "matr_,matp_,covr_,covp_,df,\\\n",
    "lab_angles_allconfs_list_list,angles_allconfs_list_list,_list,\\\n",
    "smiles_list,num_confs_list_list,num_atom_list_list,angle_group_num_list= generate_pred_confs(model, test_loader, \n",
    "                                                            loss_criterion, loss_criterion_, \n",
    "                                                            save_conf_root=\"./confs_save_\",\n",
    "                                                            chem_dataset_dir = chem_dataset_dir,\n",
    "                                                            ori_confs_path  = test_dic_path,                                                                 \n",
    "                                                            optimizer=None, \n",
    "                                                            debug = False,\n",
    "                                                            # angle_range_list = [(-20,20),(40,100)],\n",
    "                                                            k = \"2\",\n",
    "                                                            max_re = 6,\n",
    "                                                            kn = 2,\n",
    "                                                            f_percent=0.25,\n",
    "                                                            # part_batch = [0,20]\n",
    "                                                                                )\n",
    "\n",
    "\n",
    "time_save = time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime())\n",
    "print(time_save)\n",
    "pickle_.save(f\"./result_save/result_{nam}_{time_save}.pkl\", (matr_,matp_,covr_,covp_,df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e7dfb46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model save\n",
    "time_save=time.strftime(\"%Y-%m-%d_%Hh%Mm%Ss\", time.localtime())\n",
    "torch.save({\n",
    "#                 'epoch': len(Train_loss),\n",
    "                'model': model.state_dict(),\n",
    "                'model_optimizer': optimizer.state_dict(),\n",
    "\n",
    "#                 \"Train_loss_value\": Train_loss_value,\n",
    "#                 \"Train_loss_sig\": Train_loss_sig,\n",
    "#                 \"Train_loss\": Train_loss,\n",
    "#                 \"Train_acc_sig\": Train_acc_sig,\n",
    "                \n",
    "#                 \"Val_loss_value\": Val_loss_value,\n",
    "#                 \"Val_loss_sig\": Val_loss_sig,\n",
    "#                 \"Val_loss\": Val_loss,\n",
    "#                 \"Val_acc_sig\": Val_acc_sig,\n",
    "    \n",
    "},\n",
    "          f\"model_save/model_save_main_drugs-Copy3ot_{time_save}.pth\")\n",
    "\n",
    "print(\"save model to\", f\"model_save/model_save_main_drugs-Copy3ot_{time_save}.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c5eebfe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5777b0bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b562722",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pvd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
